{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0286798",
   "metadata": {},
   "source": [
    "# Welcome!\n",
    "This notebook intends to be a template for an end-to-end (or, perhaps more aptly, a discovery-analysis-publish) pipeline for using Open NASA data. In this version, there is much more documentation/tutorial, as we explain _what_ is supposed to be happening and _why_ we have done these things.\n",
    "\n",
    "## Bookend\n",
    "Bookend is a sort-of template Jupyter notebook whose purpose is to demonstrate the usefulness of semantic technologies for accelerating research and facilitating [FAIR](https://www.go-fair.org/fair-principles/) and open science.\n",
    "\n",
    "This takes the form as \"bookends\" for a normal analytical or data transformation notebook. That is, we start with an initial cell that uses semantic technologies to help discover data. This is done by searching through a _lifted_ SPASE record database. In the future, we want to support local repositories, where you can semantically describe (and thus semantically find) your own work to create reproducible scientific workflows.\n",
    "\n",
    "Then, we take a snapshot of your computational environment. For the moment, this is a semi-automated mechanism. This is further simplified as we expect the vast majority of these \"bookends\" to be executed in a [HelioCloud](https://heliocloud.org/) instance. This one way we, as data scientists can preserve experimental context for reproducibility and replicability.\n",
    "\n",
    "The next step is tie together your computational models and your computational environment.\n",
    "\n",
    "With that, you then insert your own cells.\n",
    "\n",
    "Finally, we now want to publish, even just locally, what has been produced. There are a few data fields to fill out by you, the developer. We hope it is not too onerous.\n",
    "\n",
    "Graphically, `bookend` looks like the following:\n",
    "![bookend-structure](./figures/bookend-structure.png)\n",
    "\n",
    "### Knowledge Graphs & Semantic Technologies\n",
    "Briefly, we will describe all of this metadata (i.e., data about data) in a form called a knowledge graph (KG). You can learn more about this in the following sections.\n",
    "\n",
    "* [What is Metadata](https://github.com/KGConf/open-kg-curriculum/blob/master/curriculum/modules/What_is_Metadata/What_is_Metadata.md) -- briefly, data about data.\n",
    "* [What is an Identifier](https://github.com/KGConf/open-kg-curriculum/blob/master/curriculum/modules/What_is_an_Identifier/What_is_an_Identifier.md) -- briefly, identifiers are unique IRIs for a piece of data in a particular namespace.\n",
    "* [What is a KG](https://github.com/KGConf/open-kg-curriculum/blob/master/curriculum/modules/What_is_a_Knowledge_Graph/What_is_a_Knowledge_Graph.md) -- briefly a KG is a way of relating pieces of data (nodes) through relations (edges) in a human _and_ machine understandable way. They tend to be organized according to a schema, which is frequently an ontology.\n",
    "* [What is a Taxonomy](https://github.com/KGConf/open-kg-curriculum/blob/master/curriculum/modules/What_is_a_Taxonomy/What_is_a_Taxonomy.md) -- briefly, a taxonomy is a way of hierarchically organizing a set of terms. \n",
    "* [What is an Ontology](https://github.com/KGConf/open-kg-curriculum/blob/master/curriculum/modules/What_is_an_Ontology/What_is_an_Ontology.md) -- briefly, ontologies are ways of dictating how different data can be related: for example, the child of a person should always be a person.\n",
    "\n",
    "#### Ontology Design Patterns\n",
    "To design the KG for `bookend` we make use of a set of templates for organizing the _schema_ of the KG. We call these Ontology Design Patterns (ODPs). ODPs are self-contained miniature ontologies that solve domain-invariant modeling problems. Our approach uses several to create a modular \"plug and play\" KG schema (or architecture).\n",
    "* Computational Environment\n",
    "* [Computational Observation](https://github.com/kastle-lab/computational-observation-pattern)\n",
    "* [Data Transformation](https://github.com/Data-Semantics-Laboratory/data-transformation-pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa71a07",
   "metadata": {},
   "source": [
    "## Bookend Requirements\n",
    "* [rdflib](https://rdflib.readthedocs.io/en/stable/)\n",
    "* [sparqlwrapper](https://sparqlwrapper.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de555f28",
   "metadata": {},
   "source": [
    "## The BookBEGINNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf6e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdflib is the general purpose python library for modifying a kg in memory and outputting it to a file\n",
    "import rdflib\n",
    "## Just some convenient classes to pull out\n",
    "from rdflib import URIRef, Graph, Namespace, Literal\n",
    "## namespaces are below. These are where identifiers \"live\", so to speak.\n",
    "from rdflib import OWL, RDF, RDFS, XSD, TIME\n",
    "\n",
    "# sparqlwrapper is used to query a triplestore\n",
    "import SPARQLWrapper\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6216aa76",
   "metadata": {},
   "source": [
    "## Prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c80e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some default prefixes for namespaces.\n",
    "# Which are generally useful\n",
    "pfs = {\n",
    "\"geo\": Namespace(\"http://www.opengis.net/ont/geosparql#\"),\n",
    "\"geof\": Namespace(\"http://www.opengis.net/def/function/geosparql/\"),\n",
    "\"sf\": Namespace(\"http://www.opengis.net/ont/sf#\"),\n",
    "\"wd\": Namespace(\"http://www.wikidata.org/entity/\"),\n",
    "\"wdt\": Namespace(\"http://www.wikidata.org/prop/direct/\"),\n",
    "\"dbo\": Namespace(\"http://dbpedia.org/ontology/\"),\n",
    "\"time\": Namespace(\"http://www.w3.org/2006/time#\"),\n",
    "\"ssn\": Namespace(\"http://www.w3.org/ns/ssn/\"),\n",
    "\"sosa\": Namespace(\"http://www.w3.org/ns/sosa/\"),\n",
    "\"cdt\": Namespace(\"http://w3id.org/lindt/custom_datatypes#\"),\n",
    "\"ex\": Namespace(\"https://example.com/\"),\n",
    "\"rdf\": RDF,\n",
    "\"rdfs\": RDFS,\n",
    "\"xsd\": XSD,\n",
    "\"owl\": OWL,\n",
    "\"time\": TIME\n",
    "}\n",
    "\n",
    "# The namespace and prefixes which we will use for the metadata storage\n",
    "name_space = \"https://polyneme.xyz/\"\n",
    "pfs[\"polyr\"] = Namespace(f\"{name_space}lod/resource#\")\n",
    "pfs[\"poly-ont\"] =  Namespace(f\"{name_space}lod/ontology#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b57280",
   "metadata": {},
   "source": [
    "## Storing Metadata\n",
    "It should perhaps come as no surprise the rest of the notebook, but we will store the metadata generated in this notebook in a knowledge graph. For now, it will stay in memory as `Graph` from `rdflib`. When we publish the dataset generated in this notebook, we will upload the dataset into a graph database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_kg(prefixes=pfs):\n",
    "    kg = Graph()\n",
    "    for prefix in pfs:\n",
    "        kg.bind(prefix, pfs[prefix])\n",
    "    return kg\n",
    "# rdf:type shortcut\n",
    "a = pfs[\"rdf\"][\"type\"]\n",
    "\n",
    "# Initialize an empty graph\n",
    "graph = init_kg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb294f2",
   "metadata": {},
   "source": [
    "## Accessing Your Local Graph Database\n",
    "For this notebook, we assume you are running a `developer` (i.e., non-production) Apache Jena Fuseki triplestore as your graph database. This will be useful in several different cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b7e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_loc = \"http://localhost:3030\"\n",
    "dataset = \"bookend\"\n",
    "endpoint_url = f\"{db_loc}/{dataset}\"\n",
    "endpoint = SPARQLWrapper(endpoint_url) # default location of fuseki\n",
    "endpoint.setReturnFormat(JSON)\n",
    "\n",
    "# Construct the query\n",
    "query = \"\"\"\n",
    "    PREFIX poly-ont: <https://polyneme.xyz/lod/ontology#>\n",
    "\n",
    "    SELECT *\n",
    "    WHERE {\n",
    "        ?person a poly-ont:Person .\n",
    "    }\n",
    "    \"\"\"\n",
    "# Set the query\n",
    "endpoint.setQuery(query)\n",
    "\n",
    "try:\n",
    "    ret = endpoint.queryAndConvert()\n",
    "    print(\"Connection success.\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a82b434",
   "metadata": {},
   "source": [
    "## Local SPASE\n",
    "The current expectation is that there is an RDF-ified version of the SPASE dataset locally available. For more information in generating this, see the [spase-rdf-tools](https://github.com/polyneme/spase-rdf-tools/tree/master/spase_rdf_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e041283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spase_dataset = \"spase-rdf\"\n",
    "spase_endpoint_url = f\"{db_loc}/{spase_dataset}\"\n",
    "\n",
    "spase_endpoint = SPARQLWrapper(spase_endpoint_url) # default location of fuseki\n",
    "spase_endpoint.setReturnFormat(JSON)\n",
    "\n",
    "# Construct the query\n",
    "query = \"\"\"\n",
    "    PREFIX poly-ont: <https://polyneme.xyz/lod/ontology#>\n",
    "\n",
    "    SELECT *\n",
    "    WHERE {\n",
    "        ?person a poly-ont:Person .\n",
    "    }\n",
    "    \"\"\"\n",
    "# Set the query\n",
    "spase_endpoint.setQuery(query)\n",
    "\n",
    "try:\n",
    "    ret = spase_endpoint.queryAndConvert()\n",
    "    print(\"Connection success.\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7301a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a0bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This query will be useful\n",
    "def instanceExists(uri, sparql=endpoint):\n",
    "    query = f\"\"\"\n",
    "    PREFIX poly-ont: <https://polyneme.xyz/lod/ontology#>\n",
    "\n",
    "    SELECT *\n",
    "    WHERE {{\n",
    "        <{uri}> ?p ?o .\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "    sparql.setQuery(query)\n",
    "    try:\n",
    "        ret = sparql.queryAndConvert()\n",
    "        return len(ret[\"results\"][\"bindings\"]) == 1\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e00634",
   "metadata": {},
   "source": [
    "## Capturing the Current Computational Environment\n",
    "![computational environment](./figures/computational-environment-pattern.png)\n",
    "The purpose of this is to capture the environment in which you transform data (i.e., create something new from something old). This is useful for replicability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to populate this pattern for this notebook\n",
    "\n",
    "## Mint a URI for this computational environment\n",
    "### There are many ways to create an identifier\n",
    "### We have chosen a way that encodes some information for identifiability, without searching for the label.\n",
    "comp_env_name = \"polyneme.donny.home\"\n",
    "#### Some other examples might be\n",
    "#### \"wright.cogan.campus\"\n",
    "#### \"organization.name.location\"\n",
    "comp_env_uri = pfs[\"polyr\"][comp_env_name]\n",
    "## Check to see if the computational environment exists\n",
    "if instanceExists(comp_env_uri):\n",
    "    ## Check if there needs to be updates\n",
    "    pass\n",
    "    ## Otherwise, moveon\n",
    "    pass\n",
    "else:\n",
    "    ## If you have done this before (i.e., this is not your first time running this notebook) AND your \n",
    "    ## computational environment hasn't changed.\n",
    "    graph.add( (comp_env_uri, a, pfs[\"poly-ont\"][\"ComputationalEnvironment\"]) )\n",
    "    ### TODO read comp_env from config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0241607",
   "metadata": {},
   "source": [
    "## Dataset Discovery\n",
    "This is effectively the \"Extract\" part of the ETL loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77a30b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOAA_NumericalData_GOES_13_EPS_EPEAD_E13EW_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_EPEAD_E13EW_PT1M\n",
      "NOAA_NumericalData_GOES_15_EPS_MAGPD_19MP4_PT32S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_15_EPS_MAGPD_19MP4_PT32S\n",
      "NOAA_NumericalData_GOES_13_EPS_EPEAD_A16W_PT32S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_EPEAD_A16W_PT32S\n",
      "NOAA_NumericalData_GOES_14_EPS_EPEAD_A16W_PT32S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_14_EPS_EPEAD_A16W_PT32S\n",
      "NOAA_NumericalData_GOES_13_EPS_MAGED_19ME5_PT32S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_MAGED_19ME5_PT32S\n",
      "NOAA_NumericalData_GOES_13_EPS_EPEAD_CPFLUX_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_EPEAD_CPFLUX_PT5M\n",
      "NOAA_NumericalData_GOES_15_EPS_MAGPD_19MP15_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_15_EPS_MAGPD_19MP15_PT5M\n",
      "NOAA_NumericalData_GOES_6_SEM_A_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_6_SEM_A_PT5M\n",
      "NOAA_NumericalData_GOES_1_MFM_PT3S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_1_MFM_PT3S\n",
      "NOAA_NumericalData_GOES_13_EPS_MAGPD_19MP1_PT16S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_MAGPD_19MP1_PT16S\n",
      "NOAA_NumericalData_GOES_15_EPS_HEPAD_S15_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_15_EPS_HEPAD_S15_PT1M\n",
      "NOAA_NumericalData_GOES_8_SEM_Z_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_8_SEM_Z_PT5M\n",
      "NOAA_NumericalData_GOES_15_MAG_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_15_MAG_PT1M\n",
      "NOAA_NumericalData_GOES_15_EPS_EPEAD_P27E_PT32S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_15_EPS_EPEAD_P27E_PT32S\n",
      "NOAA_NumericalData_GOES_14_EPS_EPEAD_CPFLUX_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_14_EPS_EPEAD_CPFLUX_PT5M\n",
      "NOAA_NumericalData_GOES_2_EPM_PT3S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_2_EPM_PT3S\n",
      "NOAA_NumericalData_GOES_10_HEPAD_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_10_HEPAD_PT5M\n",
      "NOAA_NumericalData_GOES_2_MFM_PT3S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_2_MFM_PT3S\n",
      "NOAA_NumericalData_GOES_15_EPS_EPEAD_P17EW_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_15_EPS_EPEAD_P17EW_PT5M\n",
      "NOAA_NumericalData_GOES_12_HEPAD_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_12_HEPAD_PT5M\n",
      "NOAA_NumericalData_GOES_13_EPS_HEPAD_AP_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_HEPAD_AP_PT1M\n",
      "NOAA_NumericalData_GOES_12_SEM_I_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_12_SEM_I_PT5M\n",
      "NOAA_NumericalData_GOES_13_EPS_MAGPD_19MP3_PT16S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_MAGPD_19MP3_PT16S\n",
      "NOAA_NumericalData_GOES_12_SEM_A_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_12_SEM_A_PT5M\n",
      "NOAA_NumericalData_GOES_14_EPS_HEPAD_S15_PT4S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_14_EPS_HEPAD_S15_PT4S\n",
      "NOAA_NumericalData_GOES_13_EPS_MAGED_19ME15_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_MAGED_19ME15_PT1M\n",
      "NOAA_NumericalData_GOES_12_MAG_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_12_MAG_PT1M\n",
      "NOAA_NumericalData_GOES_13_EPS_MAGPD_19MP15_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_MAGPD_19MP15_PT5M\n",
      "NOAA_NumericalData_GOES_11_SEM_I_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_11_SEM_I_PT5M\n",
      "NOAA_NumericalData_GOES_15_EPS_EPEAD_E13EW_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_15_EPS_EPEAD_E13EW_PT1M\n",
      "NOAA_NumericalData_GOES_7_SEM_G_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_7_SEM_G_PT5M\n",
      "NOAA_NumericalData_GOES_15_EPS_MAGPD_19MP15_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_15_EPS_MAGPD_19MP15_PT1M\n",
      "NOAA_NumericalData_GOES_9_MAG_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_9_MAG_PT5M\n",
      "NOAA_NumericalData_GOES_15_EPS_HEPAD_AP_PT32S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_15_EPS_HEPAD_AP_PT32S\n",
      "NOAA_NumericalData_GOES_13_EPS_EPEAD_P17EW_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_EPEAD_P17EW_PT1M\n",
      "NOAA_NumericalData_GOES_12_EPS_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_12_EPS_PT5M\n",
      "NOAA_NumericalData_GOES_10_SEM_H_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_10_SEM_H_PT5M\n",
      "NOAA_NumericalData_GOES_10_SEM_G_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_10_SEM_G_PT5M\n",
      "NOAA_NumericalData_GOES_10_SEM_G_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_10_SEM_G_PT1M\n",
      "NOAA_NumericalData_GOES_9_MAG_NGDC_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_9_MAG_NGDC_PT1M\n",
      "NOAA_NumericalData_GOES_14_EPS_EPEAD_A16EW_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_14_EPS_EPEAD_A16EW_PT5M\n",
      "NOAA_NumericalData_GOES_14_EPS_MAGED_19ME3_PT4S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_14_EPS_MAGED_19ME3_PT4S\n",
      "NOAA_NumericalData_GOES_11_MAG_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_11_MAG_PT1M\n",
      "NOAA_NumericalData_GOES_5_SEM_A_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_5_SEM_A_PT5M\n",
      "NOAA_NumericalData_GOES_15_EPS_MAGED_19ME15_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_15_EPS_MAGED_19ME15_PT1M\n",
      "NOAA_NumericalData_GOES_8_MAG_NGDC_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_8_MAG_NGDC_PT1M\n",
      "NOAA_NumericalData_GOES_8_EPS_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_8_EPS_PT5M\n",
      "NOAA_NumericalData_GOES_6_SEM_G_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_6_SEM_G_PT1M\n",
      "NOAA_NumericalData_GOES_13_EPS_MAGED_19ME4_PT16S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_MAGED_19ME4_PT16S\n",
      "NOAA_NumericalData_GOES_8_EPS_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_8_EPS_PT1M\n",
      "NOAA_NumericalData_GOES_7_EPM_PT3S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_7_EPM_PT3S\n",
      "NOAA_NumericalData_GOES_5_MAG_PT3S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_5_MAG_PT3S\n",
      "NOAA_NumericalData_GOES_9_SEM_A_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_9_SEM_A_PT5M\n",
      "NOAA_NumericalData_GOES_15_EPS_HEPAD_AP_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_15_EPS_HEPAD_AP_PT1M\n",
      "NOAA_NumericalData_GOES_13_EPS_HEPAD_AP_PT32S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_HEPAD_AP_PT32S\n",
      "NOAA_NumericalData_GOES_14_MAG_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_14_MAG_PT1M\n",
      "NOAA_NumericalData_GOES_14_EPS_HEPAD_AP_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_14_EPS_HEPAD_AP_PT1M\n",
      "NOAA_NumericalData_GOES_8_HEPAD_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_8_HEPAD_PT5M\n",
      "NOAA_NumericalData_GOES_5_EPS_PT3S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_5_EPS_PT3S\n",
      "NOAA_NumericalData_GOES_5_SEM_G_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_5_SEM_G_PT5M\n",
      "NOAA_NumericalData_GOES_10_MAG_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_10_MAG_PT5M\n",
      "NOAA_NumericalData_GOES_6_MAG_PT3S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_6_MAG_PT3S\n",
      "NOAA_NumericalData_GOES_13_EPS_EPEAD_P17EW_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_EPEAD_P17EW_PT5M\n",
      "NOAA_NumericalData_GOES_13_EPS_MAGPD_19MP4_PT32S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_MAGPD_19MP4_PT32S\n",
      "NOAA_NumericalData_GOES_13_EPS_EPEAD_A16E_PT32S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_EPEAD_A16E_PT32S\n",
      "NOAA_NumericalData_GOES_7_SEM_I_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_7_SEM_I_PT5M\n",
      "NOAA_NumericalData_GOES_13_EPS_MAGED_19ME1_PT2S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_MAGED_19ME1_PT2S\n",
      "NOAA_NumericalData_GOES_12_SEM_G_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_12_SEM_G_PT1M\n",
      "NOAA_NumericalData_GOES_10_MAG_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_10_MAG_PT1M\n",
      "NOAA_NumericalData_GOES_14_EPS_HEPAD_AP_PT32S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_14_EPS_HEPAD_AP_PT32S\n",
      "NOAA_NumericalData_GOES_9_SEM_G_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_9_SEM_G_PT1M\n",
      "NOAA_NumericalData_GOES_14_EPS_EPEAD_E13EW_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_14_EPS_EPEAD_E13EW_PT1M\n",
      "NOAA_NumericalData_GOES_13_MAG_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_MAG_PT1M\n",
      "NOAA_NumericalData_GOES_14_EPS_EPEAD_P1EW_PT8S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_14_EPS_EPEAD_P1EW_PT8S\n",
      "NOAA_NumericalData_GOES_13_EPS_EPEAD_E13EW_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_EPEAD_E13EW_PT5M\n",
      "NOAA_NumericalData_GOES_14_EPS_HEPAD_AP_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_14_EPS_HEPAD_AP_PT5M\n",
      "NOAA_NumericalData_GOES_Ephemeris_P1D: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_Ephemeris_P1D\n",
      "NOAA_NumericalData_GOES_6_SEM_Z_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_6_SEM_Z_PT5M\n",
      "NOAA_NumericalData_GOES_11_SEM_H_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_11_SEM_H_PT5M\n",
      "NOAA_NumericalData_GOES_10_SEM_A_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_10_SEM_A_PT5M\n",
      "NOAA_NumericalData_GOES_6_MFM_PT3S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_6_MFM_PT3S\n",
      "NOAA_NumericalData_GOES_7_SEM_H_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_7_SEM_H_PT5M\n",
      "NOAA_NumericalData_GOES_8_SEM_H_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_8_SEM_H_PT5M\n",
      "NOAA_NumericalData_GOES_15_EPS_EPEAD_A16EW_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_15_EPS_EPEAD_A16EW_PT5M\n",
      "NOAA_NumericalData_GOES_12_MAG_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_12_MAG_PT5M\n",
      "NOAA_NumericalData_GOES_15_EPS_EPEAD_E2EW_PT16S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_15_EPS_EPEAD_E2EW_PT16S\n",
      "NOAA_NumericalData_GOES_15_EPS_EPEAD_P1EW_PT8S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_15_EPS_EPEAD_P1EW_PT8S\n",
      "NOAA_NumericalData_GOES_6_EPM_PT3S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_6_EPM_PT3S\n",
      "NOAA_NumericalData_GOES_14_EPS_EPEAD_P27E_PT32S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_14_EPS_EPEAD_P27E_PT32S\n",
      "NOAA_NumericalData_GOES_15_EPS_EPEAD_E13EW_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_15_EPS_EPEAD_E13EW_PT5M\n",
      "NOAA_NumericalData_GOES_15_MAG_PT0_512S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_15_MAG_PT0_512S\n",
      "NOAA_NumericalData_GOES_8_MAG_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_8_MAG_PT5M\n",
      "NOAA_NumericalData_GOES_14_EPS_MAGED_19ME15_PT1M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_14_EPS_MAGED_19ME15_PT1M\n",
      "NOAA_NumericalData_GOES_13_EPS_EPEAD_A16EW_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_EPEAD_A16EW_PT5M\n",
      "NOAA_NumericalData_GOES_15_EPS_HEPAD_AP_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_15_EPS_HEPAD_AP_PT5M\n",
      "NOAA_NumericalData_GOES_14_EPS_EPEAD_A16E_PT32S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_14_EPS_EPEAD_A16E_PT32S\n",
      "NOAA_NumericalData_GOES_7_MFM_PT3S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_7_MFM_PT3S\n",
      "NOAA_NumericalData_GOES_14_EPS_EPEAD_E2EW_PT16S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_14_EPS_EPEAD_E2EW_PT16S\n",
      "NOAA_NumericalData_GOES_5_MFM_PT3S: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_5_MFM_PT3S\n",
      "NOAA_NumericalData_GOES_6_SEM_H_PT5M: http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_6_SEM_H_PT5M\n"
     ]
    }
   ],
   "source": [
    "# This code is currently set to query for data products (spase:NumericalData) by keyword.\n",
    "keyword = \"GOES\"\n",
    "query = f\"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX spase: <http://www.spase-group.org/data/schema/>\n",
    "\n",
    "SELECT ?label ?uri WHERE {{\n",
    "  ?uri a spase:NumericalData ;\n",
    "     spase:keyword ?\"{keyword}\" ;\n",
    "     rdfs:label ?label .\n",
    "}} LIMIT 100\n",
    "\"\"\"\n",
    "\n",
    "spase_endpoint.setQuery(query)\n",
    "try:\n",
    "    ret = spase_endpoint.queryAndConvert()\n",
    "    for res in ret[\"results\"][\"bindings\"]:\n",
    "        print(f'{res[\"label\"][\"value\"]}: {res[\"uri\"][\"value\"]}')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9890213b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can get your data from here. In the future, we will attempt to get this for you.\n",
      "https://spdf.gsfc.nasa.gov/pub/data/goes/goes13/epead-electrons/e13ew_1min/\n"
     ]
    }
   ],
   "source": [
    "# Now, you choose one of those label, URI pairs \n",
    "dataset_label = \"NOAA_NumericalData_GOES_13_EPS_EPEAD_E13EW_PT1M\"\n",
    "dataset_uri = \"http://www.spase-group.org/data/schema/NOAA_NumericalData_GOES_13_EPS_EPEAD_E13EW_PT1M\"\n",
    "\n",
    "query = f\"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX spase: <http://www.spase-group.org/data/schema/>\n",
    "\n",
    "SELECT ?actual_url WHERE {{\n",
    " <{dataset_uri}> spase:has_access_information ?o .\n",
    "  ?o spase:has_access_url ?url .\n",
    "  ?url spase:name ?\"HTTPS from SPDF\" ;\n",
    "       spase:url ?actual_url .\n",
    "}} LIMIT 100\n",
    "\"\"\"\n",
    "\n",
    "spase_endpoint.setQuery(query)\n",
    "try:\n",
    "    ret = spase_endpoint.queryAndConvert()\n",
    "    print(\"You can get your data from here. In the future, we will attempt to get this for you.\")\n",
    "    for res in ret[\"results\"][\"bindings\"]:\n",
    "        print(f'{res[\"actual_url\"][\"value\"]}')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# It is important to note that we have a record of which datasets we start with\n",
    "## Populated sample dataset names\n",
    "data_inputs = [dataset_uri]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c7aece",
   "metadata": {},
   "source": [
    "## This is where your code goes!\n",
    "This is effectively the \"Transform\" part of the ETL loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bb4c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Stuff\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb4788c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do Stuff\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c7b00c",
   "metadata": {},
   "source": [
    "## The BookEND\n",
    "The following are data fields that `bookend` needs from you in order to encode your results and publish them to the local repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee5b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO support multiple output datasets from a single script\n",
    "# It is important to provide the name and location of where the data exists\n",
    "# Optionally, you can give the format (e.g., csv)\n",
    "result_name = \"example.data\"\n",
    "result_loc  = \"https://example.org/sample/data/loc\"\n",
    "result_format = \"csv\"\n",
    "## Uniqueness is necessary!\n",
    "output_uri = pfs[\"polyr\"][f\"Data.{result_name}\"]\n",
    "if instanceExists(output_uri):\n",
    "    print(\"You have chosen a result name which exists in the graph database already.\")\n",
    "    print(\"If you continue, you will accidentally merge any metadata for this with any previously committed version.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e10eeeb",
   "metadata": {},
   "source": [
    "The following is a small, natural language blurb of what you've done in your script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2044052",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_description = \"\"\"\n",
    "text goes here!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ef1513",
   "metadata": {},
   "source": [
    "## Dataset Publishing (Internal)\n",
    "Now it is time to publish your work. This is effectively the \"Load\" part of the ETL loop.\n",
    "\n",
    "### Computational Lineage\n",
    "This is the result of combining the two ODPs (`Computational Observation` and `Data Transformation`) into something that better fits our use-case.\n",
    "\n",
    "![computational-lineage](./figures/computational-lineage-pattern.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c53d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "## Output Data\n",
    "output_uri = pfs[\"polyr\"][f\"Data.{result_name}\"]\n",
    "graph.add((output_uri, a, pfs[\"poly-ont\"][\"Data\"])) # declaration\n",
    "### Associate the dataset with its actual data (i.e., the payload)\n",
    "#### This reification exists in case we want to have other metadata about the location link (e.g., access permissions)\n",
    "payload_uri = pfs[\"polyr\"][f\"Payload.{result_name}\"]\n",
    "graph.add((payload_uri, a, pfs[\"poly-ont\"][\"Payload\"])) # declaration\n",
    "loc_uri = URIRef(result_loc)\n",
    "graph.add((output_uri, pfs[\"poly-ont\"][\"hasPayload\"], payload_uri)) # association\n",
    "graph.add((payload_uri, pfs[\"poly-ont\"][\"hasLocation\"], loc_uri)) # association\n",
    "\n",
    "### Associate the datatype to the dataset\n",
    "format_uri = pfs[\"polyr\"][f\"DataType.{result_format}\"]\n",
    "graph.add( (output_uri, pfs[\"poly-ont\"][\"hasDataType\"], format_uri) )\n",
    "\n",
    "## DataTransformation\n",
    "\n",
    "### TODO global notion of uniqueness for dt\n",
    "dt_id = 1\n",
    "dt_uri = pfs[\"polyr\"][f\"DataTransformation.{dt_id}\"]\n",
    "graph.add( (dt_uri, a, pfs[\"poly-ont\"][\"DataTransformation\"]) )\n",
    "graph.add( (dt_uri, pfs[\"poly-ont\"][\"occursInCE\"], comp_env_uri))\n",
    "### TODO spatiotemporal extent (or at least temporal extent)\n",
    "### TODO association of the DataTransformation with ComputationalModelExecution\n",
    "\n",
    "## Input Data & Data Roles\n",
    "for data_input in data_inputs:\n",
    "    input_uri = pfs[\"polyr\"][f\"Data.{data_input}\"]\n",
    "    graph.add((input_uri, a, pfs[\"poly-ont\"][\"Data\"])) # declaration\n",
    "    \n",
    "    ## Mint a new input data role\n",
    "    input_role_uri = pfs[\"polyr\"][f\"InputRole.DT{dt_id}.{data_input}\"]\n",
    "    graph.add((input_role_uri, a, pfs[\"poly-ont\"][\"InputRole\"] )) # declaration\n",
    "    graph.add((input_uri, pfs[\"poly-ont\"][\"performsInputRole\"], input_role_uri)) # association\n",
    "    graph.add((dt_uri, pfs[\"poly-ont\"][\"providesInputRole\"], input_role_uri)) # association\n",
    "\n",
    "## Output Data Role\n",
    "output_role_uri = pfs[\"polyr\"][f\"OutputRole.DT{dt_id}.{result_name}\"]\n",
    "graph.add((output_role_uri, a, pfs[\"poly-ont\"][\"InputRole\"] )) # declaration\n",
    "graph.add((output_uri, pfs[\"poly-ont\"][\"performsOutputRole\"], output_role_uri)) # association\n",
    "graph.add((dt_uri, pfs[\"poly-ont\"][\"providesOutputRole\"], output_role_uri)) # association\n",
    "pass # prevents cell output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c8782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"output.ttl\"\n",
    "temp = graph.serialize(format=\"turtle\", encoding=\"utf-8\", destination=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc488fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push to graph database\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
